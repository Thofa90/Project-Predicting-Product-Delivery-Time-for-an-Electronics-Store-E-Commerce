# Project: Predicting Product Delivery Time for an Electronics Store E-Commerce
**ðŸ“ Project Summary**

This project focuses on predicting on-time vs. delayed deliveries using machine learning techniques in the e-commerce logistics domain. After performing thorough Exploratory Data Analysis (EDA), feature engineering, and model training, multiple classifiers including Logistic Regression, SVM, Decision Tree, Random Forest, K-Nearest Neighbors (KNN), and XGBoost were evaluated. The models were assessed based on Accuracy, Precision, Recall, F1-Score, and ROC-AUC, with a special emphasis on minimizing false negatives (missed late deliveries), which is critical for business impact.

After hyperparameter tuning, XGBoost emerged as the best-performing model, striking the optimal balance between Precision and Recall, and achieving the highest ROC-AUC score. Feature importance analysis revealed that Discount Offered, Prior Purchases, and Product Weight are the most influential variables affecting delivery delays. These insights can help businesses optimize logistics and improve customer satisfaction by proactively managing high-risk deliveries.

**1. Project Title**

Predicting Delivery Delays for E-Commerce Shipments

**2. Short Description**

This project builds a machine learning model to predict whether a delivery will be on time or delayed for an electronics store. It aims to help logistics teams reduce late deliveries based on data-driven insights.

**3. Table of Contents**

**ðŸ¢ Industry Overview & Business Context**

**ðŸ“‚ Data Loading & Goal of the Project**

**ðŸ” Exploratory Data Analysis**

	1.	Basic Information & Summary
	2.	Check for Missing & Duplicates
	3.	Target Variable Distribution
	4.	Numerical Features Analysis
	5.	Boxplots of Numerical Columns per Transaction
	6.	Boxplot vs Target Variable
	7.	Categorical Features Distribution
	8.	Correlation Heatmap
	9.	Multivariate Analysis
	10.	Correlation Heatmap with Numerical and Encoded Categorical Columns

**ðŸ§¹ Data Preprocessing for Modeling**

	1.	Drop Unnecessary Column
	2.	Capping the Outliers
	3.	Handling Skewness of Numerical Columns
	4.	Encoding Categorical Variables
	5.	Train-test Split
	6.	Scale Numeric Features

**ðŸ¤– Modeling**

	1.	Baseline Modeling(Logistic Regression, SVM, Decision Tree, Random Forest, KNN, XGBoost)
	2.	Evaluation from Baseline Models
	3.	Hyperparameter Tuning All the Models
	4.	Evaluation after Hyperparameter Tuning
	5.	Feature Importance on Best Tuned Model

**âœ… Conclusion**

**4. Motivation / Problem Statement**

Late deliveries lead to customer dissatisfaction and increased logistics cost. By predicting delays in advance, the company can proactively adjust shipping plans, prioritize resources, and potentially reduce the rate of late deliveries.

**5. Dataset Overview**

- **~11,000 transactions** from an e-commerce electronics store
- **Columns include:**
  - `Warehouse_block`, `Mode_of_Shipment`, `Customer_care_calls`,
  - `Customer_rating`, `Cost_of_the_Product`, `Discount_offered`,
    `Weight_in_gms`, `Prior_purchase`,`product_Importance`,` Gender`,` Reached.on.Time_Y.N(target: 0 = on time, 1 = delayed)`
    
- **Libraries Used:**
 
	**1. Data Manipulation**
	   
	import pandas as pd, import numpy as np
	
	**2. Visualization**
	   
	import matplotlib.pyplot as plt, import seaborn as sns
	
	**3. Preprocessing**
	   
	from sklearn.preprocessing import LabelEncoder, StandardScaler
	
	from sklearn.model_selection import train_test_split
	
	**4.  Models**
	   
	from sklearn.linear_model import LogisticRegression
	
	from sklearn.svm import SVC
	
	from sklearn.tree import DecisionTreeClassifier
	
	from sklearn.ensemble import RandomForestClassifier
	
	from sklearn.neighbors import KNeighborsClassifier
	
	from xgboost import XGBClassifier
	
	**5.  Evaluation**
	   
	from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve )

**6. Exploratory Data Analysis Summary (EDA)**

ðŸ“Š Basic Information

	â€¢	âœ… Clean Dataset: No missing or duplicate values.
	â€¢	âš ï¸ Target Imbalance: 60% delayed vs. 40% on-time deliveries.

ðŸ”¢ Numerical Insights:

	â€¢	Customer Care Calls: Mostly 3â€“4 calls; no outliers or link to delivery time.
	â€¢	Customer Ratings: Evenly distributed from 1 to 5.
	â€¢	Product Cost: Most items range from $150â€“$270; peaks around $260.
	â€¢	Prior Purchases: Mostly between 2â€“5, showing moderate loyalty.
	â€¢	Discount Offered: Highly skewed; most under 10%, outliers up to 65%.
	â€¢	Weight in Grams: Bimodal; light (1000â€“2000g) and heavy (4000â€“5000g) products.

ðŸ“¦ Boxplot vs Target Variable:

	â€¢	Higher Discounts â†’ More Delays
	â€¢	Heavier Products â†’ More On-Time Deliveries
	â€¢	Cost, Ratings, and Prior Purchases show little to no impact individually.

ðŸ·ï¸ Categorical Feature Insights:

	â€¢	Warehouse Block F had the highest delay count.
	â€¢	Shipping by Ship experienced more delays vs. Flight or Road.
	â€¢	High Importance Products faced fewer delays.
	â€¢	Gender showed no meaningful difference in delay frequency.
	â€¢	High Discounts impacted delivery across all importance and customer types.

ðŸ” Correlation Summary:

	â€¢	Strongest Delay Indicators:
	â€¢	+0.40 â†’ Higher discounts = more delays
	â€¢	-0.27 â†’ Heavier products = fewer delays
	â€¢	Weak Influence: Customer behavior, product importance, and shipment type (individually).

ðŸ“Œ Final Notes:

	â€¢	Multivariate patterns (e.g., light products + ship + high discount) are more predictive than individual features.
	â€¢	EDA suggests that discount strategy and logistics optimization can significantly reduce delays.

**ðŸ§¹ 7. Data Preprocessing Steps before Modeling**

The following preprocessing steps were applied to prepare the data for machine learning:

	1.	Dropped Unnecessary Columns: Removed columns like ID that donâ€™t contribute to prediction.
	2.	Outlier Capping: Applied IQR method to cap extreme values in numerical features (e.g., prior purchases, weight, discount).
	3.	Skewness Handling: Applied log transformation to highly skewed columns like Discount_offered and Prior_purchases.
	4.	Categorical Encoding: Used Label Encoding to convert categorical variables (Warehouse_block, Mode_of_Shipment, Product_importance, Gender) into numeric form.
	5.	Train-Test Split: Split the dataset into training and testing sets using a standard 80-20 ratio for model evaluation.
	6.	Feature Scaling: Applied StandardScaler to normalize all numeric features and bring them to the same scale for consistent model performance.

**8. Modeling & Evaluation**

I have trained multiple models:

- Logistic Regression
- Bagged models (Decision Tree, Random Forest)
- Kâ€‘Nearest Neighbors
- Support Vector Machine (SVM)
- XGBoost

Metrics evaluated:

- Accuracy
- Precision
- Recall (focus on catching delayed shipments)
- F1â€‘Score
- ROCâ€‘AUC

Primary success criteria:

- High **recall** for delayed deliveries
- Balanced **F1â€‘score**

**9. Results & Interpretation**

| Model               | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------------------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.63     | 0.67      | 0.74   | 0.70     | 0.72    |
| SVM                 | 0.66     | 0.83      | 0.54   | 0.65     | 0.73    |
| Decision Tree       | 0.68     | 0.97      | 0.48   | 0.64     | 0.74    |
| Random Forest       | 0.66     | 0.78      | 0.60   | 0.68     | 0.74    |
| KNN                 | 0.63     | 0.71      | 0.65   | 0.68     | 0.72    |
| **XGBoost (best)**  | 0.66     | 0.72      | **0.71**| **0.71**   | **0.75** |

XGBoost was the best model, balancing recall and F1â€‘score while achieving top ROCâ€‘AUC.

**10. Feature Importance Insights**

ðŸ“Œ 1. XGBoost Feature Importance

	â€¢	Discount_offered is the most influential feature, contributing over 80% to the modelâ€™s decision-making.
	â€¢	Prior_purchases and Weight_in_gms have a moderate influence.
	â€¢	Features like Gender, Customer_rating, Mode_of_Shipment, and Warehouse_block have minimal impact.
	â€¢	Importance is calculated based on gain, reflecting how much a feature improves split quality.

ðŸ“Œ 2. Logistic Regression Coefficients

	â€¢	Positive coefficients (e.g., Discount_offered) increase the likelihood of delay.
	â€¢	Negative coefficients (e.g., Weight_in_gms, Prior_purchases) reduce the delay probability.
	â€¢	Coefficient magnitude shows influence, helping to interpret linear feature impact.
 
**ðŸ”® 11. Future Work**

To enhance this project further, the following steps are planned or recommended:

	â€¢	ðŸ“ˆ Hyperparameter Tuning with Cross-Validation: Extend tuning with cross-validation to improve model generalizability and reduce overfitting.
 
	â€¢	ðŸ“Š Advanced Feature Engineering: Create new features such as relative discount percentage, delivery distance (if available), or customer segmentation for better insights.
 
	â€¢	ðŸ§  Ensemble Models: Explore model stacking or blending to combine strengths of different classifiers for better performance.
 
	â€¢	ðŸ“ Geo/Time-based Features: If location or timestamp data is available, incorporate it to uncover delivery trends by region or time.
 
	â€¢	âš–ï¸ Class Imbalance Handling: Use techniques like SMOTE or class weighting to address the imbalanced delivery status labels.
 
	â€¢	ðŸ“¦ Business Integration: Collaborate with logistics teams to translate model predictions into actionable steps (e.g., flagging at-risk shipments).
 
	â€¢	ðŸ“‚ Deployment: Deploy the model via a simple web interface or API to predict delivery delays in real-time.

These enhancements can improve the modelâ€™s real-world usability and create more value for stakeholders.

**12. Usage Instructions**

  1. Open in Google Colab

You can run this project directly in Google Colab without any local setup.

Project_Predict_Delivery_Time.ipynb (Google Colab file)

 2. Load Dataset

The dataset (e_commerce.csv) is already available in this repository.
When running in Colab:

from google.colab import drive

drive.mount('/content/drive')

or reading directly from github

import pandas as pd

url = "https://raw.githubusercontent.com/Thofa90/Project-Predicting-Product-Delivery-Time-for-an-Electronics-Store-E-Commerce/main/e_commerce.csv"

df = pd.read_csv(url)

df.head()

3.	Install Required Libraries
   
   The necessary libraries are listed above in the Dataset Overview section.
  	
4.	Run All Cells
	
   Go to Runtime > Run all in Colab to execute the entire workflow.
   This includes:
	â€¢	EDA (Exploratory Data Analysis)
	â€¢	Data Preprocessing
	â€¢	Model Training & Hyperparameter Tuning
	â€¢	Evaluation & Visualizations

5.	View Results
   
	â€¢	Model comparison tables
	â€¢	Feature importance plots
	â€¢	Confusion matrices
	â€¢	ROC curves
